{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import lingtypology\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lingtypology.db_apis import Phoible\n",
    "from scipy.stats import linregress, chi2_contingency\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moran, Steven & McCloy, Daniel (eds.) 2019.\n",
      "PHOIBLE 2.0.\n",
      "Jena: Max Planck Institute for the Science of Human History.\n",
      "(Available online at http://phoible.org, Accessed on 2019-05-30.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['syllabic',\n",
       " 'short',\n",
       " 'long',\n",
       " 'consonantal',\n",
       " 'sonorant',\n",
       " 'continuant',\n",
       " 'delayedRelease',\n",
       " 'approximant',\n",
       " 'tap',\n",
       " 'trill',\n",
       " 'nasal',\n",
       " 'lateral',\n",
       " 'labial',\n",
       " 'round',\n",
       " 'labiodental',\n",
       " 'coronal',\n",
       " 'anterior',\n",
       " 'distributed',\n",
       " 'strident',\n",
       " 'dorsal',\n",
       " 'high',\n",
       " 'low',\n",
       " 'front',\n",
       " 'back',\n",
       " 'tense',\n",
       " 'retractedTongueRoot',\n",
       " 'advancedTongueRoot',\n",
       " 'periodicGlottalSource',\n",
       " 'epilaryngealSource',\n",
       " 'spreadGlottis',\n",
       " 'constrictedGlottis',\n",
       " 'fortis',\n",
       " 'raisedLarynxEjective',\n",
       " 'loweredLarynxImplosive',\n",
       " 'click']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Вытащим все бинарные фичи\n",
    "p = Phoible(aggregated=False)\n",
    "binary_features = []\n",
    "df = p.get_df()\n",
    "for col in df:\n",
    "    cond = [cell for cell in set(df[col]) if cell in ('+', '-')]\n",
    "    if cond == ['-', '+'] or cond == ['+', '-']:\n",
    "        binary_features.append(col)\n",
    "binary_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем всё про бинарные фичи для датасетов из Phoible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwrite(path, data):\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write(data)\n",
    "\n",
    "def count_stats(phoible, subset, feature, count_regressions=False):\n",
    "    phoible.subset = subset\n",
    "    data = p.get_df()\n",
    "    amount_with_feature = data[data[feature] == '+'].groupby('Glottocode').size()\n",
    "    \n",
    "    languages = [lingtypology.glottolog.get_by_glot_id(glot_id) for glot_id in amount_with_feature.index]\n",
    "    with_feature = pandas.DataFrame({\n",
    "        'language': languages,\n",
    "        feature: amount_with_feature,\n",
    "        'elevation': lingtypology.get_elevations(languages),\n",
    "    })\n",
    "    with_feature = with_feature[with_feature.elevation != '']\n",
    "    if with_feature.empty:\n",
    "        print('No data: ' + subset)\n",
    "        return\n",
    "    \n",
    "    if count_regressions:\n",
    "        #Зависит ли количество абруптивных в языках, где они суть, от высоты\n",
    "        regression_no_zeros = linregress(\n",
    "            list(map(int, with_feature[feature])),\n",
    "            list(map(int, with_feature.elevation))\n",
    "        )\n",
    "    \n",
    "    no_feature = data[~data.Glottocode.isin(list(amount_with_feature.index))]\n",
    "    no_feature = no_feature.drop_duplicates(subset='Glottocode')\n",
    "    languages = [lingtypology.glottolog.get_by_glot_id(glot_id) for glot_id in no_feature.Glottocode]\n",
    "    no_feature = pandas.DataFrame({\n",
    "        'language': languages,\n",
    "        feature: 0,\n",
    "        'elevation': lingtypology.get_elevations(languages),\n",
    "    })\n",
    "    no_feature = no_feature[no_feature.elevation != '']\n",
    "    all_ = pandas.concat((with_feature, no_feature))\n",
    "\n",
    "    #Зависит ли количество абруптивных/имплозивных во всех яхыках от высоты\n",
    "    if count_regressions:\n",
    "        regression_with_zeros = linregress(\n",
    "            list(map(int, all_[feature])),\n",
    "            list(map(int, all_.elevation))\n",
    "        )\n",
    "\n",
    "    higher = all_[all_.elevation > 1500]\n",
    "    higher = [len(higher[higher[feature] > 0]), len(higher[higher[feature] == 0])]\n",
    "    lower = all_[all_.elevation <= 1500]\n",
    "    lower = [len(lower[lower[feature] > 0]), len(lower[lower[feature] == 0])]\n",
    "    table = [higher, lower]\n",
    "    \n",
    "    #Правда ли, что, если больше 1500 метров, то ты с фичёй?\n",
    "    try:\n",
    "        chi = chi2_contingency(table)\n",
    "    except ValueError:\n",
    "        chi = [math.nan, math.nan, math.nan, math.nan]\n",
    "    \n",
    "    #Нарисуем все графики и запишем все данные в файлы\n",
    "    cdir = 'phoible_results' + os.path.sep + subset\n",
    "    if not os.path.exists(cdir):\n",
    "        os.mkdir(cdir)\n",
    "    \n",
    "    if count_regressions:\n",
    "        #График регрессия для языков с фичёй\n",
    "        plt.scatter(with_feature[feature], with_feature.elevation, color='black')\n",
    "        axes = plt.gca()\n",
    "        x_vals = np.array(axes.get_xlim())\n",
    "        y_vals = regression_no_zeros.intercept + regression_no_zeros.slope*x_vals \n",
    "        plt.plot(x_vals, y_vals, linewidth=3)\n",
    "        plt.savefig(cdir + os.path.sep + '{}_linear_regression_only.png'.format(feature), format='PNG')\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "\n",
    "        #График регрессии для всех языков по фиче\n",
    "        plt.scatter(all_[feature], all_.elevation, color='black')\n",
    "        axes = plt.gca()\n",
    "        x_vals = np.array(axes.get_xlim())\n",
    "        y_vals = regression_with_zeros.intercept + regression_with_zeros.slope*x_vals \n",
    "        plt.plot(x_vals, y_vals, linewidth=3)\n",
    "        plt.savefig(cdir + os.path.sep + '{}_linear_regression_all.png'.format(feature), format='PNG')\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "    \n",
    "        #Результаты подсчёта регрессии\n",
    "        reg_str = 'Slope:\\t{slope}\\nIntercept:\\t{intercept}\\nR_value:\\t{rvalue}\\nP_value:\\t{pvalue}'\n",
    "        fwrite(\n",
    "            cdir + os.path.sep + '{}_linear_regression_only.csv'.format(feature),\n",
    "            reg_str.format(\n",
    "                slope = regression_no_zeros.slope,\n",
    "                intercept = regression_no_zeros.intercept,\n",
    "                rvalue = regression_no_zeros.rvalue,\n",
    "                pvalue = regression_no_zeros.pvalue\n",
    "            )\n",
    "        )\n",
    "        fwrite(\n",
    "            cdir + os.path.sep + '{}_linear_regression_all.csv'.format(feature),\n",
    "            reg_str.format(\n",
    "                slope = regression_with_zeros.slope,\n",
    "                intercept = regression_with_zeros.intercept,\n",
    "                rvalue = regression_with_zeros.rvalue,\n",
    "                pvalue = regression_with_zeros.pvalue\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    #Результаты хи-квадрата\n",
    "    fwrite(\n",
    "        cdir + os.path.sep + '{}_chi2.csv'.format(feature),\n",
    "        'chi2:\\t{chi2}\\nP_value:\\t{pvalue}\\nDegrees of freedom:\\t{dof}\\nExpected:\\t{ex}'.format(\n",
    "            chi2 = chi[0],\n",
    "            pvalue = chi[1],\n",
    "            dof = chi[2],\n",
    "            ex = chi[3]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    #Чистые данные\n",
    "    with_feature.to_csv(cdir + os.path.sep + '{}_with_raw.csv'.format(feature))\n",
    "    all_.to_csv(cdir + os.path.sep + '{}_all_raw.csv'.format(feature))\n",
    "    if count_regressions:\n",
    "        return subset, chi, regression_no_zeros, regression_with_zeros\n",
    "    else:\n",
    "        return subset, chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4034: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "No data: AA\n",
      "No data: PH\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Abujmaria\n",
      "Elevations for these languages were not found: Naiki, Mising\n",
      "No data: SAPHON\n",
      "Elevations for these languages were not found: Kaliai\n",
      "Elevations for these languages were not found: Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Kuay, Endo\n",
      "Elevations for these languages were not found: Karo, Saanich, Mianmin, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Besleri, Dinka\n",
      "Elevations for these languages were not found: Frafra, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Mmani, Zayse\n",
      "Elevations for these languages were not found: Abujmaria\n",
      "Elevations for these languages were not found: Naiki, Mising\n",
      "Elevations for these languages were not found: Shipibo, Miraña\n",
      "Elevations for these languages were not found: Khithaulhu, Karo\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Kaliai\n",
      "Elevations for these languages were not found: Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Karo, Korafe\n",
      "Elevations for these languages were not found: Bikele, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo\n",
      "Elevations for these languages were not found: Pana, Dinka, Mmani\n",
      "Elevations for these languages were not found: Frafra, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Zayse\n",
      "Elevations for these languages were not found: Mising\n",
      "Elevations for these languages were not found: Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Kuay, Lorette Huron, Endo, Mvumbo\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Korafe\n",
      "Elevations for these languages were not found: Frafra, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Besleri, Zayse\n",
      "Elevations for these languages were not found: Moghamo, Dinka, Mmani, Pana\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Saanich, Kuay, Endo, Mvumbo\n",
      "Elevations for these languages were not found: Lorette Huron, Karo, Mianmin, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Besleri, Zayse\n",
      "Elevations for these languages were not found: Moghamo, Mmani\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Khithaulhu\n",
      "Elevations for these languages were not found: Shipibo, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha\n",
      "Elevations for these languages were not found: Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Mianmin, Kuay, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Karo, Lorette Huron, Endo, Saanich\n",
      "Elevations for these languages were not found: Pana, Frafra, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani\n",
      "Elevations for these languages were not found: Dinka, Zayse\n",
      "Elevations for these languages were not found: Naiki\n",
      "Elevations for these languages were not found: Mising, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha\n",
      "Elevations for these languages were not found: Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Mianmin\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Mmani, Zayse\n",
      "Elevations for these languages were not found: Besleri\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Karo, Miraña\n",
      "Elevations for these languages were not found: Khithaulhu\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Karo\n",
      "Elevations for these languages were not found: Pana, Frafra, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Dinka\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Miraña\n",
      "Elevations for these languages were not found: Karo\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "No data: SAPHON\n",
      "No data: UPSID\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "No data: AA\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "No data: GM\n",
      "No data: RA\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "No data: UPSID\n",
      "No data: SPA\n",
      "No data: AA\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "No data: RA\n",
      "No data: SAPHON\n",
      "Elevations for these languages were not found: Nama, Kaliai\n",
      "Elevations for these languages were not found: Katcha\n",
      "Elevations for these languages were not found: Ikwo\n",
      "Elevations for these languages were not found: Ezaa\n",
      "Elevations for these languages were not found: Karo, Saanich, Mianmin, Kuay, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Bikele, Endo\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Besleri, Zayse\n",
      "Elevations for these languages were not found: Moghamo, Mmani\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Karo, Saanich, Kuay, Lorette Huron, Mvumbo\n",
      "Elevations for these languages were not found: Bikele, Endo, Mianmin, Korafe\n",
      "Elevations for these languages were not found: Frafra, Ezha, Soddo, Kambe, Ikalanga, Chaha, Kauma, Efutu, Gumer, Besleri, Mmani, Zayse\n",
      "Elevations for these languages were not found: Pana, Dinka, Oko, Copi, Moghamo\n",
      "Elevations for these languages were not found: Mising\n",
      "Elevations for these languages were not found: Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Shipibo\n",
      "No data: UPSID\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "No data: AA\n",
      "No data: PH\n",
      "No data: GM\n",
      "No data: RA\n",
      "No data: SAPHON\n",
      "Elevations for these languages were not found: Nama, Katcha, Kaliai\n",
      "No data: AA\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Ezha, Soddo, Ikalanga, Chaha, Gumer, Zayse\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Kambe, Oko, Kauma, Efutu, Copi, Moghamo, Besleri, Mmani\n",
      "No data: RA\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu, Karo, Miraña\n",
      "Elevations for these languages were not found: Katcha\n",
      "Elevations for these languages were not found: Nama, Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Karo, Saanich, Mianmin, Kuay, Endo, Lorette Huron, Mvumbo, Korafe\n",
      "Elevations for these languages were not found: Copi, Pana, Besleri, Zayse\n",
      "Elevations for these languages were not found: Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Moghamo, Mmani\n",
      "Elevations for these languages were not found: Mising, Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Khithaulhu\n",
      "Elevations for these languages were not found: Shipibo, Karo, Miraña\n",
      "No data: UPSID\n",
      "No data: SPA\n",
      "No data: AA\n",
      "No data: PH\n",
      "Elevations for these languages were not found: Pana, Frafra, Dinka, Ezha, Soddo, Kambe, Ikalanga, Oko, Chaha, Kauma, Efutu, Gumer, Copi, Moghamo, Besleri, Mmani, Zayse\n",
      "No data: RA\n",
      "No data: SAPHON\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    features = binary_features#['loweredLarynxImplosive', 'raisedLarynxEjective', 'long', 'short']\n",
    "    subsets = ['UPSID', 'SPA', 'AA', 'PH', 'GM', 'RA', 'SAPHON']\n",
    "    results = {}\n",
    "    if not os.path.exists('phoible_results'):\n",
    "        os.mkdir('phoible_results')\n",
    "    p = Phoible(subset='all', aggregated=False)\n",
    "    p.show_citation = False\n",
    "    for feature in features:\n",
    "        processed_subsets = []\n",
    "        regressions_no_zeros = []\n",
    "        regressions_with_zeros = []\n",
    "        chi2s = []\n",
    "        for subset in subsets:\n",
    "            r = count_stats(p, subset, feature, count_regressions=True) if feature == 'raisedLarynxEjective' \\\n",
    "                                                else count_stats(p, subset, feature)\n",
    "            if r:\n",
    "                processed_subsets.append(r[0])\n",
    "                if feature == 'raisedLarynxEjective':\n",
    "                    regressions_no_zeros.append(r[2])\n",
    "                    regressions_with_zeros.append(r[3])\n",
    "                    chi2s.append(r[1])\n",
    "                else:\n",
    "                    chi2s.append(r[1])\n",
    "        plt.close()\n",
    "        if feature == 'raisedLarynxEjective':\n",
    "            regressed_result = pandas.DataFrame({\n",
    "                'Dataset': processed_subsets,\n",
    "                'Regression (only with feature)': ['%.015f' % r.pvalue for r in regressions_no_zeros],\n",
    "                'Regression (all languages)': ['%.015f' % r.pvalue for r in regressions_with_zeros],\n",
    "                'Chi2 Test': ['%.015f' % c[1] for c in chi2s if not math.isnan(c[1])]\n",
    "            })\n",
    "        else:\n",
    "            if not all((math.isnan(el) for el in [c[1] for c in chi2s])):\n",
    "                result = pandas.DataFrame({\n",
    "                    'Dataset': processed_subsets + ['Median'],\n",
    "                    feature: ['%.04f' % c[1] for c in chi2s] + \\\n",
    "                    [np.median([c[1] for c in chi2s if not math.isnan(c[1])])]\n",
    "                })\n",
    "                results[feature] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Regression (only with feature)</th>\n",
       "      <th>Regression (all languages)</th>\n",
       "      <th>Chi2 Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPSID</td>\n",
       "      <td>0.950559282993466</td>\n",
       "      <td>0.000044964081592</td>\n",
       "      <td>0.000032921681908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPA</td>\n",
       "      <td>0.475539733143422</td>\n",
       "      <td>0.000005592842023</td>\n",
       "      <td>0.000176784757431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PH</td>\n",
       "      <td>0.731523538203316</td>\n",
       "      <td>0.392451413030472</td>\n",
       "      <td>0.160190111324293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GM</td>\n",
       "      <td>0.038586492300174</td>\n",
       "      <td>0.000000000000000</td>\n",
       "      <td>0.000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SAPHON</td>\n",
       "      <td>0.018874875617294</td>\n",
       "      <td>0.000000005031926</td>\n",
       "      <td>0.000377241915218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset Regression (only with feature) Regression (all languages)  \\\n",
       "0   UPSID              0.950559282993466          0.000044964081592   \n",
       "1     SPA              0.475539733143422          0.000005592842023   \n",
       "2      PH              0.731523538203316          0.392451413030472   \n",
       "3      GM              0.038586492300174          0.000000000000000   \n",
       "4  SAPHON              0.018874875617294          0.000000005031926   \n",
       "\n",
       "           Chi2 Test  \n",
       "0  0.000032921681908  \n",
       "1  0.000176784757431  \n",
       "2  0.160190111324293  \n",
       "3  0.000000000000000  \n",
       "4  0.000377241915218  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame()\n",
    "for i, result in enumerate(results):\n",
    "    if i == 0:\n",
    "        df = results[result]\n",
    "    else:\n",
    "        df = pandas.merge(df, results[result], how='outer', on='Dataset')\n",
    "df = df.reindex([0, 1, 2, 3, 5, 6, 7, 4])\n",
    "df.to_csv('phoible_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>short</th>\n",
       "      <th>long</th>\n",
       "      <th>delayedRelease</th>\n",
       "      <th>tap</th>\n",
       "      <th>trill</th>\n",
       "      <th>nasal</th>\n",
       "      <th>lateral</th>\n",
       "      <th>labial</th>\n",
       "      <th>round</th>\n",
       "      <th>...</th>\n",
       "      <th>back</th>\n",
       "      <th>tense</th>\n",
       "      <th>retractedTongueRoot</th>\n",
       "      <th>advancedTongueRoot</th>\n",
       "      <th>epilaryngealSource</th>\n",
       "      <th>spreadGlottis</th>\n",
       "      <th>constrictedGlottis</th>\n",
       "      <th>fortis</th>\n",
       "      <th>loweredLarynxImplosive</th>\n",
       "      <th>click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPSID</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>0.6205</td>\n",
       "      <td>0.6106</td>\n",
       "      <td>0.9272</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>0.7388</td>\n",
       "      <td>0.1174</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3624</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5654</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPA</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>0.8311</td>\n",
       "      <td>0.4335</td>\n",
       "      <td>0.9873</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.5463</td>\n",
       "      <td>0.3787</td>\n",
       "      <td>0.3787</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.3787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8858</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.8083</td>\n",
       "      <td>0.8776</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GM</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.9499</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.6415</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.8242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RA</td>\n",
       "      <td>0.0826</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9301</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8941</td>\n",
       "      <td>0.1244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7559</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9076</td>\n",
       "      <td>0.4865</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.6491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5679</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2549</td>\n",
       "      <td>0.9051</td>\n",
       "      <td>0.7908</td>\n",
       "      <td>0.1327</td>\n",
       "      <td>0.7573</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.8665</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SAPHON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>0.3496</td>\n",
       "      <td>0.8520</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.3423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6432</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Median</td>\n",
       "      <td>0.578074</td>\n",
       "      <td>0.254949</td>\n",
       "      <td>0.610642</td>\n",
       "      <td>0.836724</td>\n",
       "      <td>0.517375</td>\n",
       "      <td>0.725022</td>\n",
       "      <td>0.320519</td>\n",
       "      <td>0.378695</td>\n",
       "      <td>0.266709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160319</td>\n",
       "      <td>0.255246</td>\n",
       "      <td>0.845344</td>\n",
       "      <td>0.255246</td>\n",
       "      <td>0.207783</td>\n",
       "      <td>0.362376</td>\n",
       "      <td>0.132809</td>\n",
       "      <td>0.808315</td>\n",
       "      <td>0.567919</td>\n",
       "      <td>0.160319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset     short      long delayedRelease       tap     trill     nasal  \\\n",
       "0   UPSID    0.7304    0.6205         0.6106    0.9272    0.5174    0.7388   \n",
       "1     SPA    0.4974    0.8311         0.4335    0.9873    0.9605       nan   \n",
       "2      GM    0.6587    0.0070         0.8435    0.8367    0.9499    0.1603   \n",
       "3      RA    0.0826    0.1125            nan    0.1125    0.0622       nan   \n",
       "5      AA       NaN    0.7559            nan    0.9076    0.4865       nan   \n",
       "6      PH       NaN    0.2549         0.9051    0.7908    0.1327    0.7573   \n",
       "7  SAPHON       NaN    0.0287         0.4856    0.3496    0.8520    0.7113   \n",
       "4  Median  0.578074  0.254949       0.610642  0.836724  0.517375  0.725022   \n",
       "\n",
       "    lateral    labial     round  ...      back     tense retractedTongueRoot  \\\n",
       "0    0.1174       nan    0.2667  ...       nan    0.2667              0.1243   \n",
       "1    0.5463    0.3787    0.3787  ...       nan       nan              0.8936   \n",
       "2    0.6415       nan    0.1603  ...    0.1603    0.1603              0.8242   \n",
       "3    0.9301       nan       nan  ...       nan       nan              0.9301   \n",
       "5    0.0491       nan       nan  ...       nan       nan              0.2252   \n",
       "6    0.3205       nan       nan  ...       nan    0.2552              0.8665   \n",
       "7    0.0000       nan       nan  ...       nan       nan                 NaN   \n",
       "4  0.320519  0.378695  0.266709  ...  0.160319  0.255246            0.845344   \n",
       "\n",
       "  advancedTongueRoot epilaryngealSource spreadGlottis constrictedGlottis  \\\n",
       "0                NaN                NaN        0.3624             0.1280   \n",
       "1             0.3787                NaN        0.8858             0.1328   \n",
       "2                NaN             0.1603        0.0480             0.0057   \n",
       "3                NaN                NaN        0.8941             0.1244   \n",
       "5                NaN                NaN        0.1302             0.6491   \n",
       "6             0.2552             0.2552        0.8090             0.1432   \n",
       "7             0.1864                NaN        0.0090             0.3423   \n",
       "4           0.255246           0.207783      0.362376           0.132809   \n",
       "\n",
       "     fortis loweredLarynxImplosive     click  \n",
       "0       NaN                 0.5654       NaN  \n",
       "1    0.8083                 0.8776       NaN  \n",
       "2       NaN                 0.2245    0.1603  \n",
       "3       NaN                 0.3215       NaN  \n",
       "5       NaN                 0.5679       NaN  \n",
       "6       NaN                 0.9455       NaN  \n",
       "7       NaN                 0.6432       NaN  \n",
       "4  0.808315               0.567919  0.160319  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "{} & Dataset &     short &      long & delayedRelease &       tap &     trill &     nasal \\\\\n",
      "\\midrule\n",
      "0 &   UPSID &    0.7304 &    0.6205 &         0.6106 &    0.9272 &    0.5174 &    0.7388 \\\\\n",
      "1 &     SPA &    0.4974 &    0.8311 &         0.4335 &    0.9873 &    0.9605 &       nan \\\\\n",
      "2 &      GM &    0.6587 &    0.0070 &         0.8435 &    0.8367 &    0.9499 &    0.1603 \\\\\n",
      "3 &      RA &    0.0826 &    0.1125 &            nan &    0.1125 &    0.0622 &       nan \\\\\n",
      "5 &      AA &       NaN &    0.7559 &            nan &    0.9076 &    0.4865 &       nan \\\\\n",
      "6 &      PH &       NaN &    0.2549 &         0.9051 &    0.7908 &    0.1327 &    0.7573 \\\\\n",
      "7 &  SAPHON &       NaN &    0.0287 &         0.4856 &    0.3496 &    0.8520 &    0.7113 \\\\\n",
      "4 &  Median &  0.578074 &  0.254949 &       0.610642 &  0.836724 &  0.517375 &  0.725022 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "I = df[['Dataset', 'short', 'long', 'delayedRelease', 'tap', 'trill', 'nasal']]\n",
    "print(I.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "{} & Dataset &   lateral &    labial &     round & labiodental & distributed & strident \\\\\n",
      "\\midrule\n",
      "0 &   UPSID &    0.1174 &       nan &    0.2667 &      0.8925 &      0.8872 &   0.5576 \\\\\n",
      "1 &     SPA &    0.5463 &    0.3787 &    0.3787 &      0.1592 &      0.2771 &   0.7159 \\\\\n",
      "2 &      GM &    0.6415 &       nan &    0.1603 &      0.5869 &      0.4575 &   0.3861 \\\\\n",
      "3 &      RA &    0.9301 &       nan &       nan &      0.9249 &         nan &   0.3215 \\\\\n",
      "5 &      AA &    0.0491 &       nan &       nan &      0.1428 &      0.8365 &      nan \\\\\n",
      "6 &      PH &    0.3205 &       nan &       nan &      0.8006 &      0.0753 &   0.4896 \\\\\n",
      "7 &  SAPHON &    0.0000 &       nan &       nan &      0.8457 &      0.0139 &   0.3705 \\\\\n",
      "4 &  Median &  0.320519 &  0.378695 &  0.266709 &    0.800579 &    0.367317 &  0.43784 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "II = df[['Dataset', 'lateral', 'labial', 'round', 'labiodental', 'distributed', 'strident']]\n",
    "print(II.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "{} & Dataset &       low &     front &      back &     tense & retractedTongueRoot & advancedTongueRoot \\\\\n",
      "\\midrule\n",
      "0 &   UPSID &    0.2667 &       nan &       nan &    0.2667 &              0.1243 &                NaN \\\\\n",
      "1 &     SPA &    0.3787 &       nan &       nan &       nan &              0.8936 &             0.3787 \\\\\n",
      "2 &      GM &    0.4430 &    0.1603 &    0.1603 &    0.1603 &              0.8242 &                NaN \\\\\n",
      "3 &      RA &    0.3215 &       nan &       nan &       nan &              0.9301 &                NaN \\\\\n",
      "5 &      AA &       nan &       nan &       nan &       nan &              0.2252 &                NaN \\\\\n",
      "6 &      PH &    0.5906 &       nan &       nan &    0.2552 &              0.8665 &             0.2552 \\\\\n",
      "7 &  SAPHON &       nan &       nan &       nan &       nan &                 NaN &             0.1864 \\\\\n",
      "4 &  Median &  0.378695 &  0.160319 &  0.160319 &  0.255246 &            0.845344 &           0.255246 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "III = df[['Dataset', 'low', 'front', 'back', 'tense', 'retractedTongueRoot', 'advancedTongueRoot']]\n",
    "print(III.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "{} & Dataset & epilaryngealSource & spreadGlottis & constrictedGlottis &    fortis & loweredLarynxImplosive &     click \\\\\n",
      "\\midrule\n",
      "0 &   UPSID &                NaN &        0.3624 &             0.1280 &       NaN &                 0.5654 &       NaN \\\\\n",
      "1 &     SPA &                NaN &        0.8858 &             0.1328 &    0.8083 &                 0.8776 &       NaN \\\\\n",
      "2 &      GM &             0.1603 &        0.0480 &             0.0057 &       NaN &                 0.2245 &    0.1603 \\\\\n",
      "3 &      RA &                NaN &        0.8941 &             0.1244 &       NaN &                 0.3215 &       NaN \\\\\n",
      "5 &      AA &                NaN &        0.1302 &             0.6491 &       NaN &                 0.5679 &       NaN \\\\\n",
      "6 &      PH &             0.2552 &        0.8090 &             0.1432 &       NaN &                 0.9455 &       NaN \\\\\n",
      "7 &  SAPHON &                NaN &        0.0090 &             0.3423 &       NaN &                 0.6432 &       NaN \\\\\n",
      "4 &  Median &           0.207783 &      0.362376 &           0.132809 &  0.808315 &               0.567919 &  0.160319 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IV = df[['Dataset', 'epilaryngealSource', 'spreadGlottis', 'constrictedGlottis', 'fortis', 'loweredLarynxImplosive', 'click']]\n",
    "print(IV.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
