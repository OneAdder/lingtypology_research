{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import lingtypology\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lingtypology.db_apis import Phoible\n",
    "from scipy.stats import linregress, chi2_contingency\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moran, Steven & McCloy, Daniel (eds.) 2019.\n",
      "PHOIBLE 2.0.\n",
      "Jena: Max Planck Institute for the Science of Human History.\n",
      "(Available online at http://phoible.org, Accessed on 2019-05-23.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['syllabic',\n",
       " 'short',\n",
       " 'long',\n",
       " 'consonantal',\n",
       " 'sonorant',\n",
       " 'continuant',\n",
       " 'delayedRelease',\n",
       " 'approximant',\n",
       " 'tap',\n",
       " 'trill',\n",
       " 'nasal',\n",
       " 'lateral',\n",
       " 'labial',\n",
       " 'round',\n",
       " 'labiodental',\n",
       " 'coronal',\n",
       " 'anterior',\n",
       " 'distributed',\n",
       " 'strident',\n",
       " 'dorsal',\n",
       " 'high',\n",
       " 'low',\n",
       " 'front',\n",
       " 'back',\n",
       " 'tense',\n",
       " 'retractedTongueRoot',\n",
       " 'advancedTongueRoot',\n",
       " 'periodicGlottalSource',\n",
       " 'epilaryngealSource',\n",
       " 'spreadGlottis',\n",
       " 'constrictedGlottis',\n",
       " 'fortis',\n",
       " 'raisedLarynxEjective',\n",
       " 'loweredLarynxImplosive',\n",
       " 'click']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Вытащим все бинарные фичи\n",
    "p = Phoible(aggregated=False)\n",
    "binary_features = []\n",
    "df = p.get_df()\n",
    "for col in df:\n",
    "    if [cell for cell in set(df[col]) if cell in ('+', '-')] == ['-', '+']:\n",
    "        binary_features.append(col)\n",
    "binary_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем всё про бинарные фичи для датасетов из Phoible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwrite(path, data):\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write(data)\n",
    "\n",
    "def count_stats(phoible, subset, feature, count_regressions=False):\n",
    "    phoible.subset = subset\n",
    "    data = p.get_df()\n",
    "    amount_with_feature = data[data[feature] == '+'].groupby('Glottocode').size()\n",
    "    \n",
    "    languages = [lingtypology.glottolog.get_by_glot_id(glot_id) for glot_id in amount_with_feature.index]\n",
    "    with_feature = pandas.DataFrame({\n",
    "        'language': languages,\n",
    "        feature: amount_with_feature,\n",
    "        'elevation': lingtypology.get_elevations(languages),\n",
    "    })\n",
    "    with_feature = with_feature[with_feature.elevation != '']\n",
    "    if with_feature.empty:\n",
    "        print('No data: ' + subset)\n",
    "        return\n",
    "    \n",
    "    if count_regressions:\n",
    "        #Зависит ли количество абруптивных в языках, где они суть, от высоты\n",
    "        regression_no_zeros = linregress(\n",
    "            list(map(int, with_feature[feature])),\n",
    "            list(map(int, with_feature.elevation))\n",
    "        )\n",
    "    \n",
    "    no_feature = data[~data.Glottocode.isin(list(amount_with_feature.index))]\n",
    "    no_feature = no_feature.drop_duplicates(subset='Glottocode')\n",
    "    languages = [lingtypology.glottolog.get_by_glot_id(glot_id) for glot_id in no_feature.Glottocode]\n",
    "    no_feature = pandas.DataFrame({\n",
    "        'language': languages,\n",
    "        feature: 0,\n",
    "        'elevation': lingtypology.get_elevations(languages),\n",
    "    })\n",
    "    no_feature = no_feature[no_feature.elevation != '']\n",
    "    all_ = pandas.concat((with_feature, no_feature))\n",
    "\n",
    "    #Зависит ли количество абруптивных/имплозивных во всех яхыках от высоты\n",
    "    if count_regressions:\n",
    "        regression_with_zeros = linregress(\n",
    "            list(map(int, all_[feature])),\n",
    "            list(map(int, all_.elevation))\n",
    "        )\n",
    "\n",
    "    higher = all_[all_.elevation > 1500]\n",
    "    higher = [len(higher[higher[feature] > 0]), len(higher[higher[feature] == 0])]\n",
    "    lower = all_[all_.elevation <= 1500]\n",
    "    lower = [len(lower[lower[feature] > 0]), len(lower[lower[feature] == 0])]\n",
    "    table = [higher, lower]\n",
    "    \n",
    "    #Правда ли, что, если больше 1500 метров, то ты с фичёй?\n",
    "    try:\n",
    "        chi = chi2_contingency(table)\n",
    "    except ValueError:\n",
    "        chi = [math.nan, math.nan, math.nan, math.nan]\n",
    "    \n",
    "    #Нарисуем все графики и запишем все данные в файлы\n",
    "    cdir = 'phoible_results' + os.path.sep + subset\n",
    "    if not os.path.exists(cdir):\n",
    "        os.mkdir(cdir)\n",
    "    \n",
    "    if count_regressions:\n",
    "        #График регрессия для языков с фичёй\n",
    "        plt.scatter(with_feature[feature], with_feature.elevation, color='black')\n",
    "        axes = plt.gca()\n",
    "        x_vals = np.array(axes.get_xlim())\n",
    "        y_vals = regression_no_zeros.intercept + regression_no_zeros.slope*x_vals \n",
    "        plt.plot(x_vals, y_vals, linewidth=3)\n",
    "        plt.savefig(cdir + os.path.sep + '{}_linear_regression_only.png'.format(feature), format='PNG')\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "\n",
    "        #График регрессии для всех языков по фиче\n",
    "        plt.scatter(all_[feature], all_.elevation, color='black')\n",
    "        axes = plt.gca()\n",
    "        x_vals = np.array(axes.get_xlim())\n",
    "        y_vals = regression_with_zeros.intercept + regression_with_zeros.slope*x_vals \n",
    "        plt.plot(x_vals, y_vals, linewidth=3)\n",
    "        plt.savefig(cdir + os.path.sep + '{}_linear_regression_all.png'.format(feature), format='PNG')\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "    \n",
    "        #Результаты подсчёта регрессии\n",
    "        reg_str = 'Slope:\\t{slope}\\nIntercept:\\t{intercept}\\nR_value:\\t{rvalue}\\nP_value:\\t{pvalue}'\n",
    "        fwrite(\n",
    "            cdir + os.path.sep + '{}_linear_regression_only.csv'.format(feature),\n",
    "            reg_str.format(\n",
    "                slope = regression_no_zeros.slope,\n",
    "                intercept = regression_no_zeros.intercept,\n",
    "                rvalue = regression_no_zeros.rvalue,\n",
    "                pvalue = regression_no_zeros.pvalue\n",
    "            )\n",
    "        )\n",
    "        fwrite(\n",
    "            cdir + os.path.sep + '{}_linear_regression_all.csv'.format(feature),\n",
    "            reg_str.format(\n",
    "                slope = regression_with_zeros.slope,\n",
    "                intercept = regression_with_zeros.intercept,\n",
    "                rvalue = regression_with_zeros.rvalue,\n",
    "                pvalue = regression_with_zeros.pvalue\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    #Результаты хи-квадрата\n",
    "    fwrite(\n",
    "        cdir + os.path.sep + '{}_chi2.csv'.format(feature),\n",
    "        'chi2:\\t{chi2}\\nP_value:\\t{pvalue}\\nDegrees of freedom:\\t{dof}\\nExpected:\\t{ex}'.format(\n",
    "            chi2 = chi[0],\n",
    "            pvalue = chi[1],\n",
    "            dof = chi[2],\n",
    "            ex = chi[3]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    #Чистые данные\n",
    "    with_feature.to_csv(cdir + os.path.sep + '{}_with_raw.csv'.format(feature))\n",
    "    all_.to_csv(cdir + os.path.sep + '{}_all_raw.csv'.format(feature))\n",
    "    if count_regressions:\n",
    "        return subset, chi, regression_no_zeros, regression_with_zeros\n",
    "    else:\n",
    "        return subset, chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "No data: AA\n",
      "No data: PH\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Soddo, Ezha, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Abujmaria\n",
      "Elevations for these languages were not found: Naiki, Mising\n",
      "No data: SAPHON\n",
      "Elevations for these languages were not found: Kaliai\n",
      "Elevations for these languages were not found: Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Kuay, Endo, Bikele\n",
      "Elevations for these languages were not found: Mianmin, Saanich, Korafe, Mvumbo, Karo, Lorette Huron\n",
      "Elevations for these languages were not found: Pana, Besleri, Dinka\n",
      "Elevations for these languages were not found: Chaha, Efutu, Frafra, Zayse, Ezha, Mmani, Copi, Kambe, Oko, Ikalanga, Kauma, Soddo, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Abujmaria\n",
      "Elevations for these languages were not found: Naiki, Mising\n",
      "Elevations for these languages were not found: Miraña, Shipibo\n",
      "Elevations for these languages were not found: Karo, Khithaulhu\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai\n",
      "Elevations for these languages were not found: Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Korafe, Karo\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Saanich, Mvumbo, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Pana, Dinka, Mmani\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Copi, Kambe, Oko, Ikalanga, Kauma, Soddo, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Mising\n",
      "Elevations for these languages were not found: Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña\n",
      "Elevations for these languages were not found: Shipibo, Khithaulhu\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Kuay, Mvumbo, Endo, Lorette Huron\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Saanich, Korafe, Karo\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Copi, Kambe, Oko, Ikalanga, Kauma, Soddo, Gumer\n",
      "Elevations for these languages were not found: Pana, Dinka, Mmani, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Saanich, Mvumbo, Endo, Kuay\n",
      "Elevations for these languages were not found: Korafe, Karo, Mianmin, Lorette Huron\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer\n",
      "Elevations for these languages were not found: Mmani, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Khithaulhu\n",
      "Elevations for these languages were not found: Karo, Miraña, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Nama, Katcha\n",
      "Elevations for these languages were not found: Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Kuay\n",
      "Elevations for these languages were not found: Saanich, Karo, Endo, Lorette Huron\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Ezha, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Soddo, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Zayse, Dinka\n",
      "Elevations for these languages were not found: Naiki\n",
      "Elevations for these languages were not found: Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Nama, Katcha\n",
      "Elevations for these languages were not found: Kaliai\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Mianmin\n",
      "Elevations for these languages were not found: Chaha, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Besleri\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Shipibo\n",
      "Elevations for these languages were not found: Khithaulhu\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Karo\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Soddo, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Dinka\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Karo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Saanich, Karo, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Soddo, Ezha, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "No data: SAPHON\n",
      "No data: UPSID\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "No data: AA\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Saanich, Karo, Lorette Huron, Endo, Kuay\n",
      "No data: GM\n",
      "No data: RA\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "No data: UPSID\n",
      "No data: SPA\n",
      "No data: AA\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Saanich, Karo, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Soddo, Ezha, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "No data: RA\n",
      "No data: SAPHON\n",
      "Elevations for these languages were not found: Kaliai, Nama\n",
      "Elevations for these languages were not found: Katcha\n",
      "Elevations for these languages were not found: Ikwo\n",
      "Elevations for these languages were not found: Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Korafe, Mvumbo, Karo, Saanich, Lorette Huron, Kuay\n",
      "Elevations for these languages were not found: Endo, Bikele\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Soddo, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer\n",
      "Elevations for these languages were not found: Mmani, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Saanich, Mvumbo, Karo, Lorette Huron, Kuay\n",
      "Elevations for these languages were not found: Korafe, Endo, Mianmin, Bikele\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Ezha, Mmani, Kambe, Ikalanga, Kauma, Soddo, Gumer\n",
      "Elevations for these languages were not found: Copi, Oko, Pana, Dinka, Moghamo\n",
      "Elevations for these languages were not found: Mising\n",
      "Elevations for these languages were not found: Naiki, Abujmaria\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu\n",
      "Elevations for these languages were not found: Shipibo\n",
      "No data: UPSID\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "No data: AA\n",
      "No data: PH\n",
      "No data: GM\n",
      "No data: RA\n",
      "No data: SAPHON\n",
      "Elevations for these languages were not found: Kaliai, Nama, Katcha\n",
      "No data: AA\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Saanich, Karo, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Chaha, Zayse, Ezha, Ikalanga, Soddo, Gumer\n",
      "Elevations for these languages were not found: Besleri, Efutu, Frafra, Mmani, Copi, Kambe, Oko, Pana, Kauma, Dinka, Moghamo\n",
      "No data: RA\n",
      "Elevations for these languages were not found: Karo, Miraña, Khithaulhu, Shipibo\n",
      "Elevations for these languages were not found: Katcha\n",
      "Elevations for these languages were not found: Kaliai, Nama\n",
      "Elevations for these languages were not found: Ikwo, Ezaa\n",
      "Elevations for these languages were not found: Mianmin, Bikele, Korafe, Mvumbo, Saanich, Karo, Lorette Huron, Endo, Kuay\n",
      "Elevations for these languages were not found: Zayse, Pana, Besleri, Copi\n",
      "Elevations for these languages were not found: Chaha, Efutu, Frafra, Soddo, Ezha, Mmani, Kambe, Oko, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "Elevations for these languages were not found: Naiki, Mising, Abujmaria\n",
      "Elevations for these languages were not found: Khithaulhu\n",
      "Elevations for these languages were not found: Karo, Miraña, Shipibo\n",
      "No data: UPSID\n",
      "No data: SPA\n",
      "No data: AA\n",
      "No data: PH\n",
      "Elevations for these languages were not found: Chaha, Besleri, Efutu, Frafra, Zayse, Soddo, Ezha, Mmani, Copi, Kambe, Oko, Pana, Ikalanga, Kauma, Dinka, Gumer, Moghamo\n",
      "No data: RA\n",
      "No data: SAPHON\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    features = binary_features#['loweredLarynxImplosive', 'raisedLarynxEjective', 'long', 'short']\n",
    "    subsets = ['UPSID', 'SPA', 'AA', 'PH', 'GM', 'RA', 'SAPHON']\n",
    "    results = {}\n",
    "    if not os.path.exists('phoible_results'):\n",
    "        os.mkdir('phoible_results')\n",
    "    p = Phoible(subset='all', aggregated=False)\n",
    "    p.show_citation = False\n",
    "    for feature in features:\n",
    "        processed_subsets = []\n",
    "        regressions_no_zeros = []\n",
    "        regressions_with_zeros = []\n",
    "        chi2s = []\n",
    "        for subset in subsets:\n",
    "            r = count_stats(p, subset, feature, count_regressions=True) if feature == 'raisedLarynxEjective' \\\n",
    "                                                else count_stats(p, subset, feature)\n",
    "            if r:\n",
    "                processed_subsets.append(r[0])\n",
    "                if feature == 'raisedLarynxEjective':\n",
    "                    regressions_no_zeros.append(r[2])\n",
    "                    regressions_with_zeros.append(r[3])\n",
    "                    chi2s.append(r[1])\n",
    "                else:\n",
    "                    chi2s.append(r[1])\n",
    "        plt.close()\n",
    "        if feature == 'raisedLarynxEjective':\n",
    "            regressed_result = pandas.DataFrame({\n",
    "                'Dataset': processed_subsets,\n",
    "                'Regression (only with feature)': ['%.015f' % r.pvalue for r in regressions_no_zeros],\n",
    "                'Regression (all languages)': ['%.015f' % r.pvalue for r in regressions_with_zeros],\n",
    "                'Chi2 Test': ['%.015f' % c[1] for c in chi2s if not math.isnan(c[1])]\n",
    "            })\n",
    "        else:\n",
    "            if not all((math.isnan(el) for el in [c[1] for c in chi2s])):\n",
    "                result = pandas.DataFrame({\n",
    "                    'Dataset': processed_subsets + ['Median'],\n",
    "                    feature: ['%.015f' % c[1] for c in chi2s] + \\\n",
    "                    [np.median([c[1] for c in chi2s if not math.isnan(c[1])])]\n",
    "                })\n",
    "                results[feature] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Regression (only with feature)</th>\n",
       "      <th>Regression (all languages)</th>\n",
       "      <th>Chi2 Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPSID</td>\n",
       "      <td>0.950559282993466</td>\n",
       "      <td>0.000044964081592</td>\n",
       "      <td>0.000032921681908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPA</td>\n",
       "      <td>0.475539733143422</td>\n",
       "      <td>0.000005592842023</td>\n",
       "      <td>0.000176784757431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PH</td>\n",
       "      <td>0.731523538203316</td>\n",
       "      <td>0.392451413030472</td>\n",
       "      <td>0.160190111324293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GM</td>\n",
       "      <td>0.038586492300174</td>\n",
       "      <td>0.000000000000000</td>\n",
       "      <td>0.000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SAPHON</td>\n",
       "      <td>0.018874875617294</td>\n",
       "      <td>0.000000005031926</td>\n",
       "      <td>0.000377241915218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset Regression (only with feature) Regression (all languages)  \\\n",
       "0   UPSID              0.950559282993466          0.000044964081592   \n",
       "1     SPA              0.475539733143422          0.000005592842023   \n",
       "2      PH              0.731523538203316          0.392451413030472   \n",
       "3      GM              0.038586492300174          0.000000000000000   \n",
       "4  SAPHON              0.018874875617294          0.000000005031926   \n",
       "\n",
       "           Chi2 Test  \n",
       "0  0.000032921681908  \n",
       "1  0.000176784757431  \n",
       "2  0.160190111324293  \n",
       "3  0.000000000000000  \n",
       "4  0.000377241915218  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame()\n",
    "for i, result in enumerate(results):\n",
    "    if i == 0:\n",
    "        df = results[result]\n",
    "    else:\n",
    "        df = pandas.merge(df, results[result], how='outer', on='Dataset')\n",
    "df = df.reindex([0, 1, 2, 3, 5, 6, 7, 4])\n",
    "df.to_csv('phoible_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>short</th>\n",
       "      <th>long</th>\n",
       "      <th>delayedRelease</th>\n",
       "      <th>tap</th>\n",
       "      <th>trill</th>\n",
       "      <th>nasal</th>\n",
       "      <th>lateral</th>\n",
       "      <th>labial</th>\n",
       "      <th>round</th>\n",
       "      <th>...</th>\n",
       "      <th>back</th>\n",
       "      <th>tense</th>\n",
       "      <th>retractedTongueRoot</th>\n",
       "      <th>advancedTongueRoot</th>\n",
       "      <th>epilaryngealSource</th>\n",
       "      <th>spreadGlottis</th>\n",
       "      <th>constrictedGlottis</th>\n",
       "      <th>fortis</th>\n",
       "      <th>loweredLarynxImplosive</th>\n",
       "      <th>click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPSID</td>\n",
       "      <td>0.730419672713904</td>\n",
       "      <td>0.620511832347898</td>\n",
       "      <td>0.610642343383107</td>\n",
       "      <td>0.927227831574490</td>\n",
       "      <td>0.517374876065757</td>\n",
       "      <td>0.738778553384912</td>\n",
       "      <td>0.117359459300816</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.266708754830617</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.266708754830617</td>\n",
       "      <td>0.124305390808548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.362376239087925</td>\n",
       "      <td>0.127966661243741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.565424335905343</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPA</td>\n",
       "      <td>0.497428201856995</td>\n",
       "      <td>0.831051620467149</td>\n",
       "      <td>0.433495995608892</td>\n",
       "      <td>0.987328733151668</td>\n",
       "      <td>0.960465877523403</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.546315254202639</td>\n",
       "      <td>0.378695084030329</td>\n",
       "      <td>0.378695084030329</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.893600396371416</td>\n",
       "      <td>0.378695084030329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.885780256031918</td>\n",
       "      <td>0.132809308454472</td>\n",
       "      <td>0.808314671561521</td>\n",
       "      <td>0.877635260028769</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GM</td>\n",
       "      <td>0.658720709358762</td>\n",
       "      <td>0.006986869609299</td>\n",
       "      <td>0.843461590175212</td>\n",
       "      <td>0.836723984942173</td>\n",
       "      <td>0.949874476413349</td>\n",
       "      <td>0.160318898286199</td>\n",
       "      <td>0.641480155123851</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.160318898286199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160318898286199</td>\n",
       "      <td>0.160318898286199</td>\n",
       "      <td>0.824181832981538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.160318898286199</td>\n",
       "      <td>0.048041180787709</td>\n",
       "      <td>0.005662174866105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.224522852678438</td>\n",
       "      <td>0.160318898286199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RA</td>\n",
       "      <td>0.082592769214860</td>\n",
       "      <td>0.112500539872434</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.112500539872434</td>\n",
       "      <td>0.062153287592109</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.930140153281564</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.930140153281564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.894069996254116</td>\n",
       "      <td>0.124427864171340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.321514293603832</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755885144448328</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.907576007474965</td>\n",
       "      <td>0.486470077078995</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.049114227976661</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.225210272657504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.130185303900607</td>\n",
       "      <td>0.649133295389312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567918568194081</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254948600104008</td>\n",
       "      <td>0.905140088960697</td>\n",
       "      <td>0.790767254178321</td>\n",
       "      <td>0.132695245671694</td>\n",
       "      <td>0.757345703655888</td>\n",
       "      <td>0.320518850359147</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.255246281705311</td>\n",
       "      <td>0.866506575329833</td>\n",
       "      <td>0.255246281705311</td>\n",
       "      <td>0.255246281705311</td>\n",
       "      <td>0.808968585395863</td>\n",
       "      <td>0.143196976509720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.945547335556590</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SAPHON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028694279598890</td>\n",
       "      <td>0.485630464439581</td>\n",
       "      <td>0.349615490771714</td>\n",
       "      <td>0.852018339010430</td>\n",
       "      <td>0.711266316433214</td>\n",
       "      <td>0.000001332869234</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186412393772568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009041205598374</td>\n",
       "      <td>0.342260126597239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643234605638429</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Median</td>\n",
       "      <td>0.578074</td>\n",
       "      <td>0.254949</td>\n",
       "      <td>0.610642</td>\n",
       "      <td>0.836724</td>\n",
       "      <td>0.517375</td>\n",
       "      <td>0.725022</td>\n",
       "      <td>0.320519</td>\n",
       "      <td>0.378695</td>\n",
       "      <td>0.266709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160319</td>\n",
       "      <td>0.255246</td>\n",
       "      <td>0.845344</td>\n",
       "      <td>0.255246</td>\n",
       "      <td>0.207783</td>\n",
       "      <td>0.362376</td>\n",
       "      <td>0.132809</td>\n",
       "      <td>0.808315</td>\n",
       "      <td>0.567919</td>\n",
       "      <td>0.160319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset              short               long     delayedRelease  \\\n",
       "0   UPSID  0.730419672713904  0.620511832347898  0.610642343383107   \n",
       "1     SPA  0.497428201856995  0.831051620467149  0.433495995608892   \n",
       "2      GM  0.658720709358762  0.006986869609299  0.843461590175212   \n",
       "3      RA  0.082592769214860  0.112500539872434                nan   \n",
       "5      AA                NaN  0.755885144448328                nan   \n",
       "6      PH                NaN  0.254948600104008  0.905140088960697   \n",
       "7  SAPHON                NaN  0.028694279598890  0.485630464439581   \n",
       "4  Median           0.578074           0.254949           0.610642   \n",
       "\n",
       "                 tap              trill              nasal            lateral  \\\n",
       "0  0.927227831574490  0.517374876065757  0.738778553384912  0.117359459300816   \n",
       "1  0.987328733151668  0.960465877523403                nan  0.546315254202639   \n",
       "2  0.836723984942173  0.949874476413349  0.160318898286199  0.641480155123851   \n",
       "3  0.112500539872434  0.062153287592109                nan  0.930140153281564   \n",
       "5  0.907576007474965  0.486470077078995                nan  0.049114227976661   \n",
       "6  0.790767254178321  0.132695245671694  0.757345703655888  0.320518850359147   \n",
       "7  0.349615490771714  0.852018339010430  0.711266316433214  0.000001332869234   \n",
       "4           0.836724           0.517375           0.725022           0.320519   \n",
       "\n",
       "              labial              round  ...               back  \\\n",
       "0                nan  0.266708754830617  ...                nan   \n",
       "1  0.378695084030329  0.378695084030329  ...                nan   \n",
       "2                nan  0.160318898286199  ...  0.160318898286199   \n",
       "3                nan                nan  ...                nan   \n",
       "5                nan                nan  ...                nan   \n",
       "6                nan                nan  ...                nan   \n",
       "7                nan                nan  ...                nan   \n",
       "4           0.378695           0.266709  ...           0.160319   \n",
       "\n",
       "               tense retractedTongueRoot advancedTongueRoot  \\\n",
       "0  0.266708754830617   0.124305390808548                NaN   \n",
       "1                nan   0.893600396371416  0.378695084030329   \n",
       "2  0.160318898286199   0.824181832981538                NaN   \n",
       "3                nan   0.930140153281564                NaN   \n",
       "5                nan   0.225210272657504                NaN   \n",
       "6  0.255246281705311   0.866506575329833  0.255246281705311   \n",
       "7                nan                 NaN  0.186412393772568   \n",
       "4           0.255246            0.845344           0.255246   \n",
       "\n",
       "  epilaryngealSource      spreadGlottis constrictedGlottis             fortis  \\\n",
       "0                NaN  0.362376239087925  0.127966661243741                NaN   \n",
       "1                NaN  0.885780256031918  0.132809308454472  0.808314671561521   \n",
       "2  0.160318898286199  0.048041180787709  0.005662174866105                NaN   \n",
       "3                NaN  0.894069996254116  0.124427864171340                NaN   \n",
       "5                NaN  0.130185303900607  0.649133295389312                NaN   \n",
       "6  0.255246281705311  0.808968585395863  0.143196976509720                NaN   \n",
       "7                NaN  0.009041205598374  0.342260126597239                NaN   \n",
       "4           0.207783           0.362376           0.132809           0.808315   \n",
       "\n",
       "  loweredLarynxImplosive              click  \n",
       "0      0.565424335905343                NaN  \n",
       "1      0.877635260028769                NaN  \n",
       "2      0.224522852678438  0.160318898286199  \n",
       "3      0.321514293603832                NaN  \n",
       "5      0.567918568194081                NaN  \n",
       "6      0.945547335556590                NaN  \n",
       "7      0.643234605638429                NaN  \n",
       "4               0.567919           0.160319  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
